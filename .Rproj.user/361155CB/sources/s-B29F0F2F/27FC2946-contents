#==================================================================================================
# Lab #5b: Data Manipulation in the Tidyverse 2
# Date: October 27, 2021
# Creator: Curry James Cunningham, College of Fisheries and Ocean Sciences, UAF
#
#Purpose: To explore alternative methods for manipulating, summarizing, and exploring data.
#
#
#==================================================================================================
#NOTES:

#==================================================================================================
library(datasets)
library(tidyverse)
library(dplyr)
library(ggthemes)

# Exercise 0: Setting up our Workspace ====================================
# First, set your working directory
# setwd()

# We can save our working directory path as an object
wd <- getwd()

# Define the location of our data desired subfolder
dir.data <- file.path(wd, "data")

# Next, we can create a /data subfolder within our working directory
?dir.create
dir.create(file.path(wd, "data"))

# COPY YOUR DATA FILES INTO THIS NEW DATA SUBFOLDER

# Exercise 1: Mutating and Transmuting =====================================
# mutate() adds new variables and preserves existing existing variables (columns)

# Perhaps we want to add a new variable to our Bristol Bay data frame that is the European Age designation

head(bay.data)

# We can paste together our freshwater age and ocean age, with a period in 
# between and add this variable to our data frame

# This will give the European age designation

# To do so we can use the mutate() function in the dplyr package

?dplyr::mutate

# Notice we can specify the package for a function by leading the function
#   with the package name and two colons "::"

bay.data <- dplyr::mutate(bay.data, age=paste0(fwAge, ".", oAge))
head(bay.data)

# NOTE: This operation is equivalent to using the $ to define a new column

bay.data$age_alt <- paste0(bay.data$fwAge, ".", bay.data$oAge)

head(bay.data)

# Are these new columns the same, lets use our == logic comparison
bay.data$age==bay.data$age_alt

# Remember our logic statements operate element-wise, so it might be easier to
#   use this logical comparison in conjunction with the unique() function
#     to see if all element-wise comparisons are equal
unique(bay.data$age==bay.data$age_alt)

# Lets convert this new variable to a factor
bay.data$age <- factor(bay.data$age) 

# No FALSEs returned, so we have confirmed that these two approaches to adding a
#   new column (variable) are equivalent.

# OK, now that we have proven this to ourselves lets remove age_alt as it is unnecessary
?select

bay.data <- select(bay.data, -age_alt)

head(bay.data)

# Now we can easily plot our return abundance by age class for each river system
#   using the geom_col() function for columns

ggplot(data=bay.data, aes(x=retYr, y=ret)) +
  geom_col() +
  facet_wrap(~System, scales="free_y") +
  xlab("Return Year") +
  ylab("Return Abundance (thousands)")

# By adding a fill= aesthetic we can color components of our bars
#   based on our factor for age

ggplot(data=bay.data, aes(x=retYr, y=ret, fill=age)) +
  geom_col() +
  facet_wrap(~System, scales="free_y") +
  xlab("Return Year") +
  ylab("Return Abundance (thousands)")

#   By default geom_col() will stack components of bars comprised of each age class

# By changing the position= argument in geom_col() from position="stack"
#   to position="dodge"
?geom_col

# We will zoom into the most recent years by subsetting our data object
#   so we can more clearly see the influence of the position= argument

ggplot(data=bay.data[bay.data$retYr>=2015 & bay.data$System=="Egegik",], 
        aes(x=retYr, y=ret, fill=age)) +
  geom_col(position="stack") +
  facet_wrap(~System, scales="free_y") +
  xlab("Return Year") +
  ylab("Return Abundance (thousands)")


ggplot(data=bay.data[bay.data$retYr>=2015 & bay.data$System=="Egegik",], 
       aes(x=retYr, y=ret, fill=age)) +
  geom_col(position="dodge") +
  facet_wrap(~System, scales="free_y") +
  xlab("Return Year") +
  ylab("Return Abundance (thousands)")
# Now all the bars for separate age classes are no longer stacked atop each other
# But this really isn't all that helpful for our purposes, if we want to 
#   simultaneously look at annual totals, but also see the trends in age composition

# NOTE: We can easily convert our code to display numbers in millions of sockeye salmon
#         by dividing our ret variable (that is in thousands) by 1e3
ggplot(data=bay.data, aes(x=retYr, y=ret/1e3, fill=age)) +
  geom_col() +
  facet_wrap(~System, scales="free_y") +
  xlab("Return Year") +
  ylab("Return Abundance (millions)")

# We can use this another of the standard R data sets to further explore the mutate()
#   function
library(MASS)
data(Aids2)

?Aids2

str(Aids2)

# Two of the variables are the date of Diagnosis (diag) and the date of death or end 
#  of observation (death). These are Julian dates.

# If we wanted to calculate the time interval (in days) between diagnosis and 
#   death we could use mutate() 
#     and add this value as another attribute (column) called "interval"

head(Aids2)

Aids2_expanded <- mutate(Aids2, interval=(death-diag))

head(Aids2_expanded)

# The transmute function, on the other hand, will calculate these "interval"
#  but discard the other columns

?transmute

Aids2_transmute <- transmute(Aids2, interval=(death-diag))

head(Aids2_transmute)

# Honestly, I don't ever need transmute() but it is nice to know it is in our
#   dplyr tookit.

# Challenge A: Mutating Data Frames  =============================

# To explore how we can add variables to our data frame we will use the 
#   Covid-19 data set we have already explored, which includes
#     both daily and cumulative cases of Covid-19, and those cases that 
#       were for hospitalized and deceased individuals.

covid.2021.dat <- read.csv(file=file.path(dir.data, "covid-2021.csv"))

head(covid.2021.dat)

# Please use the mutate() function to calculate the proportion of daily cases
#   that were hospitalized, and those that were deceased.

# Please call these new variables (columns) "prop.hospitalized" and "prop.deceased",
#   respectively. Then please plot histograms of each of these new variables
#     across days, to get a sense of the proportions.
# To ease the comparison, please use a standard x-axis range: 0-1

# SOLUTION: ----------------------------------------








# --------------------------------------------------

# Exercise 2: Introducing the Pipe =========================================

# A useful programming concept called a "pipe" is a way to link multiple
#   operations together seamlessly.

# The pipe operator is: %>%

# Usually we will pipe an object into a function or some other type of operation


# Here we can pipe a simple vector of values into sum() function
a <- 1:5
a

a %>% sum()

# But we can also use the pipe to our advantage when subsetting our data
#   prior to plotting

# First, we can pipe our bay.data data frame object into our ggplot() function


bay.data %>% ggplot(aes(x=retYr, y=ret, fill=age)) +
  geom_col() +
  facet_wrap(~System, scales="free_y")

# Let's combine a filtering operation for the years we want to plot,
#   with our call to the ggplot() function

bay.data %>% filter(retYr>=1980) %>% 
  ggplot(aes(x=retYr, y=ret, fill=age)) +
  geom_col() +
  facet_wrap(~System, scales="free_y")

# Or perhaps we want to filter our data prior to plotting to only plot the 
#   four major age classes 1.2, 1.3, 2.2, and 2.3

bay.data %>% filter(age %in% c("1.2","1.3","2.2","2.3")) %>% 
  ggplot(aes(x=retYr, y=ret, fill=age)) +
  geom_col() +
  facet_wrap(~System, scales="free_y")

# I don't like those colors, lets change our fill palette
#   Personally, I like the colorblind palette in the ggthemes package
library(ggthemes)

bay.data %>% filter(age %in% c("1.2","1.3","2.2","2.3")) %>% 
  ggplot(aes(x=retYr, y=ret, fill=age)) +
  geom_col() +
  facet_wrap(~System, scales="free_y") +
  scale_fill_colorblind()

# Going back to our Aids2 data set lets perform two successive operations:
# 1) filter to only include male patients
# 2) Plot density plots of the age distribution of diagnosed patients, with
#      each density plot colored separately by the Australian state

?Aids2


Aids2 %>% filter(sex=="M") %>% ggplot(aes(age, fill=state)) +
  geom_density(alpha=0.25)


# Perhaps we want to filter our data for just Queensland, and compare the
#   age distribution of male and female patients

Aids2 %>% filter(state=="QLD") %>% ggplot(aes(age, fill=sex)) +
  geom_density(alpha=0.25)

# Exercise 3: Summarizing Data =============================================
# The dplyr package offers a useful function for summarizing our data, which can be incredibly useful. 
# In practice the summarize() function describing how the summary will be generated, will often be 
#   combined with a call to the group_by() function. 

# The group_by() function describes the categorical variables across which we will summarize.
?group_by

# The summarize() function describes the summary actions you want to take, and the name of the 
#   new summary variables (columns).
?summarize()


# Pipes simply allow you to link multiple actions together and are specified
#  with the %>% character

head(bay.data)

# Let's summarize Bristol Bay salmon abundance by return Year

bay.data %>%  group_by(retYr) %>% 
  summarize(total=sum(ret))

# We can add a call to the filter() function to our pipped operation
#   Here we can calculate total Bristol Bay run size by year
#    for return years after and including 1970

bay.data %>% filter(retYr>=1970) %>%  group_by(retYr) %>% 
  summarize(total=sum(ret))

# We can easily extend this to summarize the total (sum) of return abundance by 
#   river system and return year
head(bay.data)

bay.data %>% filter(retYr>=1970) %>%  group_by(retYr, System) %>% 
  summarize(total=sum(ret))



# Challenge B: Summarizing Data ===============================
# For this challenge please use the "bay.data" data frame to create
#   a summary for each Bristol Bay river system.

# This summary should hold the mean and standard deviation of return abundance
#   across return years AFTER AND INCLUDING 1970 for each river system.

# SOLUTION: --------------------------------







# ------------------------------------------


# We can use the Aids2 data set to explore more piping operations

# Using the Aids2 data set, lets both calculate the interval between diagnosis and death AND
#  filter for only women under 30
library(MASS)
data(Aids2)

new.data <- Aids2 %>% filter(sex=="F", age<30) %>% mutate(interval=(death-diag))

head(new.data, n=3)
unique(new.data$sex)
max(new.data$age)

# We have successfully combined two steps into one


# We will use the mutated version of the Aids2 data set where the interval has been calculated:

Aids2_expanded <- Aids2 %>% mutate(interval=(death-diag))

# Now, lets summarize the mean of the time interval for males and females

Aids2_expanded %>% group_by(sex) %>% summarize("mean"=mean(interval))

# We add different variable combinations by which we summarize, by adding more variables to 
#  group_by()

Aids2_expanded %>% group_by(sex, state) %>% summarize("mean"=mean(interval))

# This is the average interval across patients, within each sex by state combination

# We can also add additional summary statistics...
Aids2_expanded %>% group_by(sex, state) %>% summarize("mean"=mean(interval),
                                                      "sd"=sd(interval))

# Now we have summarized the mean and standard deviation interval, across patients,
#  for each state by sex by state combination. 


# Exercise 4: Joining Data Sets ============================================
# It is often necessary to bring together multiple data objects by a linking variable.
#  This could be a patient ID that links diet and health information. The dplyr package has a full range of joins

# To visualize the different types of joins, we will use some small data sets on bands, members, and instruments

band_members

band_instruments


# "Mutating" joins combine variables from the left and right data sets
#   left %>% _join(right)

# All of our joins will attempt to guess the common variable (column) name
#   that will be used for joining

# inner_join() only returns elements that are common to both data sets
band_members %>% inner_join(band_instruments)

# left_join() maintains the full extent of the left data set, and will add NA's for missing
#  attributes from the right dataset
band_members %>% left_join(band_instruments)

# right_join() is the opposite of the left_join() maintaining full extent of right hand object
band_members %>% right_join(band_instruments)

# full_join() maintains full extent of both objects
band_members %>% full_join(band_instruments)


# In general it is better practice to specify the name of the variable or variables (columns)
#  by which you are joining

# If the names of the linking columns are the same, you can specify the "by"
#  argument as one string.

band_members %>% inner_join(band_instruments, by = "name")

# However, if the joining columns have different names in the two data sets, 
#  specify by as a vector of the linking column names from the 1) left and 2) right hand data sets.

band_members
band_instruments2

# Name and artist are the linking columns in the two data sets

band_members %>% full_join(band_instruments2, by = c("name" = "artist"))


# Challenge C: Joining Datasets ========================================

harvest.dat <- read.csv(file=file.path(dir.data, "Alaska-Salmon-Harvests.csv"))
lookup.dat <- read.csv(file=file.path(dir.data, "Harvest-Area-Lookup.csv"))

# To practice the joins we have learned, please join the "lookup.dat" object to the "harvest.dat"
#   object in order to associate a more useful name with each management area.

# Please create a new data frame called "new.harvest.dat" that associates the correct "Area" with each observation (row)
#   in the "harvest.dat" object. Finally, print the head of this object.

# SOLUTION: -----------------------------------------







# ---------------------------------------------------


# Exercise 5: Working with Dates ===============================================

# If you work with timeseries data you will inevitably run into the challenge 
#   of working with date types.

# Working with dates is a frequent challenge in R. 
#   This is because R will typically read in date columns in your data frame as 
#      character strings, or even worse factors, which they are not. 
# Dates have a sequential order and have additional attributes, 
#   the month, year, time, ect. 

# Here we will explore several ways of converting dates into the correct format

# The first is the as.Date() function in base R

?as.Date

# Let's begin by trying to convert a date as a character string
#   to a Date format
as.Date('5/27/1987')

# What happened?
# R is telling us that our date character string DOES NOT have a "standard
#   unambiguous format"

# Basically, it doesn't know how to parse this into a Date type.


# So, we can give it some help by pre-specifying the format.

as.Date('5/27/1987', format = '%m/%d/%Y')


# Let's look at another common format:
#   Here again we can specify the format of our dates with the format=
#     argument to the as.Date() function

# We can look up the % encodings for different date formats in strptime
?strptime

as.Date('May 27, 1987', format = '%B %d, %Y') 

# And another common format ...
as.Date('27MAY87', format = '%d%b%y')

# Or finally another

as.Date('27may87', format = '%d%b%y') 

# As you are probably all aware, if we are entering dates in Excel
#   we can define the format.

# How we format dates in our input file will dictate how we specify the format
#   in as.Date

# In the previous examples we were feeding in a single date in quotes

# But as.Date will work just as well on objects containing dates.

# Either a single date

Curry_birthday <- "May 27, 1987"

Curry_birthday

as.Date(Curry_birthday, format = '%B %d, %Y') 

# What is the structure of the converted date format

Curry_birthday_standard <- as.Date(Curry_birthday, format = '%B %d, %Y') 

typeof(Curry_birthday_standard)

str(Curry_birthday_standard)

# Or a vector of dates, on which as.Date() will operate element-wise

Curry_birthday_festival <- c("May 26, 1987", "May 27, 1987", "May 28, 1987")

Curry_birthday_festival

as.Date(Curry_birthday_festival, format = '%B %d, %Y') 

# This will return the a date object with values in date format

Curry_birthday_festival_standard <- as.Date(Curry_birthday_festival, format = '%B %d, %Y') 

str(Curry_birthday_festival_standard)

length(Curry_birthday_festival_standard)

# And we can extract elements of this object in a standard way.
Curry_birthday_festival_standard[1]

Curry_birthday_festival_standard[2]

Curry_birthday_festival_standard[1:2]

Curry_birthday_festival_standard[c(1,3)]


# We can also call several functions to extract parts of the date type

?weekdays

weekdays(Curry_birthday_festival_standard)

months(Curry_birthday_festival_standard)

# To extract the day of year, we need to specify the origin as a date

julian(Curry_birthday_festival_standard, origin=as.Date("1987-01-01"))

festival.doy <- as.numeric(julian(Curry_birthday_festival_standard,
                                    origin=as.Date("1987-01-01")))

festival.doy

# The lubridate package contains additional functionality for working with dates
library(lubridate)

Curry_birthday

?as_date

as_date(Curry_birthday)

# Here again we will need to specify the format

# Lets look up the correct % encoding

?srptime

as_date(Curry_birthday, format="%b %d, %Y")

# Now let's look at a more realistic example with our covid-19 data set
head(covid.2021.dat)

str(covid.2021.dat)

# Our date reported is currently read in as character strings... no good

# But what is our date format?

# We can look at the first element to decide
covid.2021.dat$Date.Reported[1]

# Ok, we have the numeric month, the numeric day, and the year with the century.
#   since we have the century, we need %Y (capital Y, vs lowercase y)

as_date(covid.2021.dat$Date.Reported[1], format="%m/%d/%Y")

# Always good to test this first to make sure you have the right format before
#   we change anything.

# Now we can create a new column with the proper date format

covid.2021.dat <- covid.2021.dat %>% mutate(date=as_date(Date.Reported, format="%m/%d/%Y"))

# What have we just done?

str(covid.2021.dat)

# But, why does this matter?

# Well what happens if we try to plot the cumulative number of cases by date
#   based on the old "Date.Reported" variable (column)

ggplot(covid.2021.dat, aes(x=Date.Reported, y=All.Cases..Cumulative.)) +
  geom_line()

# This doesn't look right.
# That is because we are trying to specify our x-axis variable based on a 
#   character string, which ggplot() tries to convert to a factor

# Thankfully geom_path gives us a somewhat helpful warning, but plots anyway

# Let's try this again with our new date variable "date" specifying the x-axis
#   reference
ggplot(covid.2021.dat, aes(x=date, y=All.Cases..Cumulative.)) +
  geom_line()

# Now that works better

# The same thing is true when plotting with base R, we want to use
#   date formats

plot(All.Cases..Cumulative.~Date.Reported, data=covid.2021.dat)

plot(All.Cases..Cumulative.~date, data=covid.2021.dat)

# One of the geoms we haven't explored in detail is geom_area()
#   This may be a more useful way to plot this relationship

# We can specify a single color in the aesthetic mapping: fill="red"

covid.2021.dat %>% ggplot(aes(x=date, y=All.Cases..Cumulative., fill="red")) +
  geom_area()

# But this will add a rather odd and uninformative legend
#   We can exclude something from being included in a legend by
#     specifying the show.legend=FALSE argument in our geom_area() call

covid.2021.dat %>% ggplot(aes(x=date, y=All.Cases..Cumulative., fill="red")) +
  geom_area(show.legend=FALSE)

# To make this figure even easier to interpret, we can make the fill
#   partially transparent to show the gridlines

covid.2021.dat %>% ggplot(aes(x=date, y=All.Cases..Cumulative., fill="red")) +
  geom_area(show.legend=FALSE, alpha=0.5) +
  xlab("Date") + ylab("Cumulative Covid-19 Cases") +
  ggtitle("Alaska Covid-19 Cases")

# Another way to view these data is a comparison of daily Covid-19 cases between years

# To do so we need to add an additional column with years

# We can extract the years with the years function in lubridate
#   and day of year with the yday() function
?years

covid.2021.dat <- covid.2021.dat %>% mutate(year=year(date), doy=yday(date))

str(covid.2021.dat)

# Now let's compare potential 
p <- covid.2021.dat %>% ggplot(aes(x=date, y=All.Cases)) +
       geom_area(show.legend=FALSE, alpha=0.5) +
       xlab("Date") + ylab("Daily Covid-19 Cases") +
       ggtitle("Alaska Covid-19 Cases")
plot(p)

# Let's fill based on year to show the breakpoint

# We can layer this onto our existing ggplot object "p",
#   we will also change show.legend to TRUE so we see the years.
#     Note, we will need to treat year as a categorical variable (factor)

p <- covid.2021.dat %>% ggplot(aes(x=date, y=All.Cases, fill=factor(year))) +
        geom_area(show.legend=TRUE, alpha=0.5) +
        xlab("Date") + ylab("Daily Covid-19 Cases") +
        ggtitle("Alaska Covid-19 Cases")
plot(p)

# As I've stated before I'm not keen on the default ggplot color scheme,
#   so we can update it easily by adding a layer to our ggplot object

p.2 <- p + scale_fill_colorblind()
plot(p.2)

# We can easily layer on a smoothed trend line

p.3 <- p.2 + stat_smooth(se=FALSE)
plot(p.3)

# We can even layer on a call to facet_wrap
p.4 <- p.3 + facet_wrap(~factor(year))
plot(p.4)

# But if we don't want the same x-axis limits we need to set scale=
p.4 <- p.3 + facet_wrap(~factor(year), scales="free_x")
plot(p.4)

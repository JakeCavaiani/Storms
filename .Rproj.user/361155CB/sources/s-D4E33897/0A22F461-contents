# press Command+Option+O to collapse all sections and get an overview of the workflow! #
### C2-fDOM 06-06:08-13 ###

#### READ ME ####

# The purpose of this script is to explain variation in daily averaged (to remove diel seasonality) CPCRW 2017 fDOM data using covariates in multivariate state space models.


# There are multiple possible approaches for attributing variation to covariates. I will start with # 2 here:

# 1) Set the drift term (U) to zero. This forces covariates (C) to try to explain season-long trends (as well as within-season variation??). 
## Candidate models with no drift term (U=0):
### a) no covariates
### b) all covariates (excluding combinations with any highly collinear pairs of vairables)
### c) n models for all possible combinations of covariates (excluding combinations with any highly collinear pairs of vairables)
# The model with the lowest AIC + best diagnostics contains the covariates that best explain a season-long trend. 

# 2) Allow the drift term (U) to be estimated. This forces covariates to try to explain within-season variation. 
## Candidate models with drift term (U="u"):
### a) no covariates
### b) all covariates (excluding combinations with any highly collinear pairs of vairables)
### c) n models for all possible combinations of covariates (excluding combinations with any highly collinear pairs of vairables)
# The model with the lowest AIC + best diagnostics contains the covariates that best explain within-season variation. 
# I will do (a) and (b) for now and compare them. Note that (b) requires multiple sets of covariates to avoid collinearity while still considering all variables. 

# Highly collinear pairs were determined for datasets for each site both with and w/o the step change. Correlation >0.5 was considered a source of high collinearity. 

### Response Variables: ###
# "fDOM_Tc_TURBc_filled_mean"                  

### Explanatory Variables: ### 
# "Temp_C_filled_mean"                                         
# "SpCond_uScm_filled_mean"                            
# "Turbidity_FNU_filled_mean"                           
# "Discharge_Lsec_mean"                       
# "airtemp_100.1200cm_mean_mean"     [same for all catchments]       
# "precip_mm_mean"                   [same for all catchments]       
# "cum_precip_mm_mean"               [same for all catchments] 
# "daylength"                        [same for all catchments] 
# "step"                             [same for all catchments]

# fDOM.daily is CPCRW.2017_may22.00.00.00_sept01.00.00.00.csv, with the following edits:
## fDOM_Tc_TURBc, stream temp., conductivity, turbidity, precip., and cumulative precip. were subset from the rest of the data.
## Small gaps (<12 hrs of data) were filled using an arima + kalman routine.
## Large gaps (>= 12 hrs of data) were filled with linear interpolation. 
## The head and tail of the dataframe was trimmed so that time series of all parameters in all sites started and stopped on the same date/time with no NAs. 
### This resulted in a timeframe of 2017-06-06 to 2017-08-23.
## 1 obs./15 min data were averaged by day to give daily averages for all variables.
## Daylength (calculated from the geosphere::daylength function) and mean daily air temp (from the CRREL met station at CPCRW, averaged between 100 and 1200 cm height) were added as predictors. 
## A dummy variable was added as a predictor to indicate dates during which the step change was occuring (08-14 and 08-15) and 0 for all other dates. 


#### libraries ####
library(stats)
library(MARSS)
library(forecast)
library(datasets)
library(here)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(forecast)
library(zoo)
library(xts)
library(imputeTS)
library(Hmisc)
library(data.table)
library(gridExtra)
library(bbmle)
library(grid)


#### load data ####

fDOM.daily = read.csv("Stitched_data/fDOM.daily.csv", row.names = 1)
fDOM.daily$day = as.POSIXct(fDOM.daily$day, "%Y-%m-%d", tz="America/Anchorage")

#### data wrangling fDOM dat ####

## subset daily data by site and date range ##
C2 = subset(fDOM.daily, site.ID == "C2")
C2.r = subset(C2, day < as.POSIXct("2017-08-14", tz="America/Anchorage"))

## z-score ##
dat = as.vector(C2.r$fDOM_Tc_TURBc_filled_mean)
#dat = log10(dat)
dat <- scale(dat, center=TRUE, scale=F)

## check for NAs ##
any(is.na((dat)))

## plot ##
plot(dat, type="b")

## transpose for MARSS ##
yy <- t(matrix(dat))

## set varNames ##
varNames = "C2.r.fDOM"

#### data wrangling covars ####

## change "cum_precip_mm_mean" to "cum_prec_mm_mean" so that var selection method doesn't confuse it with "precip_mm_mean" ##
names(C2.r) = c("day", "site.ID","date_timeAK_mean","Temp_C_filled_mean","SpCond_uScm_filled_mean","precip_mm_mean", "cum_prec_mm_mean","Discharge_Lsec_mean","airtemp_100.1200cm_mean_mean","Turbidity_FNU_filled_mean","fDOM_Tc_TURBc_filled_mean","date_timeAK_sd","Temp_C_filled_sd","SpCond_uScm_filled_sd","precip_mm_sd","cum_prec_mm_sd","Discharge_Lsec_sd","airtemp_100.1200cm_mean_sd","Turbidity_FNU_filled_sd","fDOM_Tc_TURBc_filled_sd","daylength", "step" )

cov <- C2.r %>% select("daylength", "Temp_C_filled_mean", "SpCond_uScm_filled_mean", "Turbidity_FNU_filled_mean", "Discharge_Lsec_mean", "airtemp_100.1200cm_mean_mean", "precip_mm_mean", "cum_prec_mm_mean")

covNames = colnames(cov)


## generate all non-collinear cov lists with at least 4 covs ##

b = sapply(1:8, function(i) (combn(covNames, i, simplify = F)))
c <- unlist(b,recursive=FALSE)

## remove collinear pairs ##
d = c[lapply(c, function(x) length(grep("daylength",x,value=FALSE) & 
                                     grep("Discharge_Lsec_mean",x,value=FALSE))) == 0]

e = d[lapply(d, function(x) length(grep("daylength",x,value=FALSE) & 
                                     grep("Temp_C_filled_mean",x,value=FALSE))) == 0]

f = e[lapply(e, function(x) length(grep("daylength",x,value=FALSE) & 
                                     grep("SpCond_uScm_filled_mean",x,value=FALSE))) == 0]

g = f[lapply(f, function(x) length(grep("Discharge_Lsec_mean",x,value=FALSE) & 
                                     grep("Temp_C_filled_mean",x,value=FALSE))) == 0]

h = g[lapply(g, function(x) length(grep("Discharge_Lsec_mean",x,value=FALSE) & 
                                     grep("SpCond_uScm_filled_mean",x,value=FALSE))) == 0]

i = h[lapply(h, function(x) length(grep("precip_mm_mean",x,value=FALSE) & 
                                     grep("Turbidity_FNU_filled_mean",x,value=FALSE))) == 0]
# choose lists with at least 4 variables:
to.remove <- sapply(i, function(i) length(i) < 4)
j <- i[!to.remove]



#### set MARSS model parms  ####

# number of variates
nn <- dim(yy)[1]

### inputs to process model ###
# i.e., the model that estimates the hidden random walk from the data

BB = matrix("b")
UU = matrix("u") # Allow a drift to term for the random walk to be estimated

## cc ##
cc <- t(scale(cov))
col_set <- rainbow(nrow(cc))
layout(matrix(c(1,2),nrow=1), width=c(5,3)) 
par(mar=c(5,4,4,0))
matplot(t(cc), type="l", col = col_set, lty=1)
mm <- nrow(cc)
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("center", colnames(cov),col=col_set,cex=0.5,fill=col_set)

par(mar=c(5,4,4,2))
par(mfrow=c(1,1))

## CC ##
CC <- "unconstrained"

## QQ ##
QQ = matrix("q")


### inputs to observtion model ###
# i.e., the model that estimates the response variable

## ZZ ##
ZZ=matrix(1)
## AA ##
AA=matrix(0)
## DD ##
DD=matrix(0) # matrix of coefficients to be estimated for covariates in an observation model. 
## dd ##
dd=matrix(0) # these is the covariate matrix in the observation model. I could put in all analytical errors (I think?), or attribute variation to observation rather than process (??), but I won't do either for now. 


## RR ##
# Models with random walks in the process model must have r (observation model error) set to the instrument's error in the same units as the data. These are:
fDOM_R = 0.07 #QSU
RR = matrix(fDOM_R)

###

x0 = yy[,1,drop=FALSE] 
list.C2.r_fDOM = list(
  B=BB, 
  U=UU,
  C=CC,
  c=cc,
  Q=QQ,
  Z=ZZ, 
  A=AA, 
  D=DD,
  d=DD,
  R=RR,
  x0=x0, 
  tinitx=1
)

#### run model with all covs ####

mod.C2.r_fDOM <- MARSS(y=yy, 
                       model=list.C2.r_fDOM,
                       control=list(maxit= 1000, allow.degen=TRUE), fit=TRUE)

est.C2.r_fDOM = MARSSparamCIs(mod.C2.r_fDOM, method = "hessian", alpha = 0.05, nboot = 1000)
est.C2.r_fDOM

### C2.r-fDOM 06-06:08-23 MARSS model covariate results - All covs ###

# FIGURE OF C MATRIX COEFS AND 95% CIS

CIs = cbind(
  est.C2.r_fDOM$par$U,
  est.C2.r_fDOM$par.lowCI$U,
  est.C2.r_fDOM$par.upCI$U)
CIs = as.data.frame(CIs)
names(CIs) = c("Est.", "Lower", "Upper")
CIs$parm = rownames(CIs)

all = ggplot(CIs, aes(parm, Est.)) + 
  geom_point(position=position_dodge(width=0.3), size=2) + 
  geom_errorbar(aes(ymin=Lower, ymax=Upper),position=position_dodge(width=0.3), width=0.2) + 
  theme_bw(base_size=12)+ 
  geom_hline(aes(yintercept=0), linetype="dashed")+
  coord_flip()+ ggtitle("C2.r 06-06:08-23 fDOM")
all


#### "for" loop to run all non-collinear cov lists with at least 4 covs ####

# This loop runs the MARSS function for all the combinations of model parameters contained in the matrix 'combos'
#and stores the output in the list 'mod.output'
mod.output <- list()
est.output <- list()
plot.output <-list()

for(i in 1:15){
  cov <- C2.r %>% select(j[[i]])
  cc <- t(scale(cov))
  #select model structure and parameters
  #change this so that it uses combo matrix to index correct parameters
  mod.list <- list(B=BB, 
                   U=UU,
                   C=CC,
                   c=cc,
                   Q=QQ,
                   Z=ZZ, 
                   A=AA, 
                   D=DD,
                   d=DD,
                   R=RR, 
                   x0=x0, 
                   tinitx=1)
  #MARSS function call, can change number of iterations if desired
  mod <- MARSS(y=yy, 
               model=mod.list, 
               control=list(maxit= 1000, allow.degen=TRUE), fit=TRUE)
  #put MARSS output into a list
  mod.output[[i]] <- mod 
  #give the model output the right name
  #names(mod.output)[i] <- mod.names[i]
  # estimates
  est = MARSSparamCIs(mod.output[[i]], method = "hessian", alpha = 0.05, nboot = 1000)
  est.output[[i]] <- est 
  # plot estimates
  CIs = cbind(
    est.output[[i]]$par$U,
    est.output[[i]]$par.lowCI$U,
    est.output[[i]]$par.upCI$U)
  CIs = as.data.frame(CIs)
  names(CIs) = c("Est.", "Lower", "Upper")
  CIs$parm = rownames(CIs)
  m.p = ggplot(CIs, aes(parm, Est.)) + 
    geom_point(position=position_dodge(width=0.3), size=2) + 
    geom_errorbar(aes(ymin=Lower, ymax=Upper),position=position_dodge(width=0.3), width=0.2) + 
    theme_bw(base_size=12)+ 
    geom_hline(aes(yintercept=0), linetype="dashed")+
    coord_flip()+ ggtitle(paste("C2.r 06-06:08-23 fDOM", i))
  plot.output[[i]] <- m.p 
  ggsave(m.p, filename = paste("Output from analyses/22_CPCRW_2017_C2.r.fDOM_mods/mod.plot.", i, ".pdf",sep=""), width=6, height=6, units = "in")
}

mod.output
est.output
plot.output


#### run model with collinear covs - (16) ####

## change cc ##
# z-score the covars to facilitate comparisons
cov <- C2.r %>% select( "Temp_C_filled_mean", "SpCond_uScm_filled_mean", "Turbidity_FNU_filled_mean", "Discharge_Lsec_mean", "airtemp_100.1200cm_mean_mean", "cum_prec_mm_mean")

coVarNames <- names(cov)
cov_in <- coVarNames

cc <- t(scale(cov))
col_set <- rainbow(nrow(cc))
layout(matrix(c(1,2),nrow=1), width=c(5,3)) 
par(mar=c(5,4,4,0))
matplot(t(cc), type="l", col = col_set, lty=1)
mm <- nrow(cc)
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("center", coVarNames,col=col_set,cex=0.5,fill=col_set)
par(mar=c(5,4,4,2))
par(mfrow=c(1,1))

list.C2.r_fDOM = list(
  B=BB, 
  U=UU,
  C=CC,
  c=cc,
  Q=QQ,
  Z=ZZ, 
  A=AA, 
  D=DD,
  d=DD,
  R=RR,
  x0=x0, 
  tinitx=1
)


mod.16.C2.r_fDOM <- MARSS(y=yy, 
                          model=list.C2.r_fDOM,
                          control=list(maxit= 1000, allow.degen=TRUE), fit=TRUE)

mod.output[[16]] = mod.16.C2.r_fDOM

est.16.C2.r_fDOM = MARSSparamCIs(mod.16.C2.r_fDOM, method = "hessian", alpha = 0.05, nboot = 1000)
est.16.C2.r_fDOM
est.output[[16]] = est.16.C2.r_fDOM

# plot estimates
CIs = cbind(
  est.output[[16]]$par$U,
  est.output[[16]]$par.lowCI$U,
  est.output[[16]]$par.upCI$U)
CIs = as.data.frame(CIs)
names(CIs) = c("Est.", "Lower", "Upper")
CIs$parm = rownames(CIs)
m.p = ggplot(CIs, aes(parm, Est.)) + 
  geom_point(position=position_dodge(width=0.3), size=2) + 
  geom_errorbar(aes(ymin=Lower, ymax=Upper),position=position_dodge(width=0.3), width=0.2) + 
  theme_bw(base_size=12)+ 
  geom_hline(aes(yintercept=0), linetype="dashed")+
  coord_flip()+ ggtitle(paste("C2.r 06-06:08-23 fDOM", "16"))
plot.output[[16]] <- m.p 
ggsave(m.p, filename = paste("Output from analyses/22_CPCRW_2017_C2.r.fDOM_mods/mod.plot.", 16, ".pdf",sep=""), width=6, height=6, units = "in")



#### run model with collinear covs - (17) ####

## change cc ##
# z-score the covars to facilitate comparisons
cov <- C2.r %>% select( "Temp_C_filled_mean", "SpCond_uScm_filled_mean", "precip_mm_mean", "Discharge_Lsec_mean", "airtemp_100.1200cm_mean_mean", "cum_prec_mm_mean")

coVarNames <- names(cov)
cov_in <- coVarNames

cc <- t(scale(cov))
col_set <- rainbow(nrow(cc))
layout(matrix(c(1,2),nrow=1), width=c(5,3)) 
par(mar=c(5,4,4,0))
matplot(t(cc), type="l", col = col_set, lty=1)
mm <- nrow(cc)
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("center", coVarNames,col=col_set,cex=0.5,fill=col_set)
par(mar=c(5,4,4,2))
par(mfrow=c(1,1))

list.C2.r_fDOM = list(
  B=BB, 
  U=UU,
  C=CC,
  c=cc,
  Q=QQ,
  Z=ZZ, 
  A=AA, 
  D=DD,
  d=DD,
  R=RR,
  x0=x0, 
  tinitx=1
)

mod.17.C2.r_fDOM <- MARSS(y=yy, 
                          model=list.C2.r_fDOM,
                          control=list(maxit= 1000, allow.degen=TRUE), fit=TRUE)

mod.output[[17]] = mod.17.C2.r_fDOM

est.17.C2.r_fDOM = MARSSparamCIs(mod.17.C2.r_fDOM, method = "hessian", alpha = 0.05, nboot = 1000)
est.17.C2.r_fDOM
est.output[[17]] = est.17.C2.r_fDOM

# plot estimates
CIs = cbind(
  est.output[[17]]$par$U,
  est.output[[17]]$par.lowCI$U,
  est.output[[17]]$par.upCI$U)
CIs = as.data.frame(CIs)
names(CIs) = c("Est.", "Lower", "Upper")
CIs$parm = rownames(CIs)
m.p = ggplot(CIs, aes(parm, Est.)) + 
  geom_point(position=position_dodge(width=0.3), size=2) + 
  geom_errorbar(aes(ymin=Lower, ymax=Upper),position=position_dodge(width=0.3), width=0.2) + 
  theme_bw(base_size=12)+ 
  geom_hline(aes(yintercept=0), linetype="dashed")+
  coord_flip()+ ggtitle(paste("C2.r 06-06:08-23 fDOM", "17"))
plot.output[[17]] <- m.p 
ggsave(m.p, filename = paste("Output from analyses/22_CPCRW_2017_C2.r.fDOM_mods/mod.plot.", 17, ".pdf",sep=""), width=6, height=6, units = "in")



#### run model with collinear covs - (18) ####

## change cc ##
# z-score the covars to facilitate comparisons
cov <- C2.r %>% select( "Temp_C_filled_mean", "SpCond_uScm_filled_mean", "precip_mm_mean", "Turbidity_FNU_filled_mean", "airtemp_100.1200cm_mean_mean", "cum_prec_mm_mean")

coVarNames <- names(cov)
cov_in <- coVarNames

cc <- t(scale(cov))
col_set <- rainbow(nrow(cc))
layout(matrix(c(1,2),nrow=1), width=c(5,3)) 
par(mar=c(5,4,4,0))
matplot(t(cc), type="l", col = col_set, lty=1)
mm <- nrow(cc)
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("center", coVarNames,col=col_set,cex=0.5,fill=col_set)
par(mar=c(5,4,4,2))
par(mfrow=c(1,1))

list.C2.r_fDOM = list(
  B=BB, 
  U=UU,
  C=CC,
  c=cc,
  Q=QQ,
  Z=ZZ, 
  A=AA, 
  D=DD,
  d=DD,
  R=RR,
  x0=x0, 
  tinitx=1
)

mod.18.C2.r_fDOM <- MARSS(y=yy, 
                          model=list.C2.r_fDOM,
                          control=list(maxit= 1000, allow.degen=TRUE), fit=TRUE)

mod.output[[18]] = mod.18.C2.r_fDOM

est.18.C2.r_fDOM = MARSSparamCIs(mod.18.C2.r_fDOM, method = "hessian", alpha = 0.05, nboot = 1000)
est.18.C2.r_fDOM
est.output[[18]] = est.18.C2.r_fDOM

# plot estimates
CIs = cbind(
  est.output[[18]]$par$U,
  est.output[[18]]$par.lowCI$U,
  est.output[[18]]$par.upCI$U)
CIs = as.data.frame(CIs)
names(CIs) = c("Est.", "Lower", "Upper")
CIs$parm = rownames(CIs)
m.p = ggplot(CIs, aes(parm, Est.)) + 
  geom_point(position=position_dodge(width=0.3), size=2) + 
  geom_errorbar(aes(ymin=Lower, ymax=Upper),position=position_dodge(width=0.3), width=0.2) + 
  theme_bw(base_size=12)+ 
  geom_hline(aes(yintercept=0), linetype="dashed")+
  coord_flip()+ ggtitle(paste("C2.r 06-06:08-23 fDOM", "18"))
plot.output[[18]] <- m.p 
ggsave(m.p, filename = paste("Output from analyses/22_CPCRW_2017_C2.r.fDOM_mods/mod.plot.", 18, ".pdf",sep=""), width=6, height=6, units = "in")



#### model comparisons (plot effects, AIC) ####

### run model with no covs ###

list.null = list(
  B='diagonal and unequal', 
  U=matrix("u"), 
  Q=matrix("q"),
  Z=matrix(1), 
  A=matrix(0), 
  R=matrix(fDOM_R),
  x0=x0, 
  tinitx=1
)
mod.null <- MARSS(yy, model=list.null)



grid.arrange(plot.output[[1]],plot.output[[2]],plot.output[[3]],
             plot.output[[4]],plot.output[[5]],plot.output[[6]],
             plot.output[[7]],plot.output[[8]],plot.output[[9]],
             nrow = 3)

grid.arrange(plot.output[[10]],plot.output[[11]],plot.output[[12]],
             plot.output[[13]],plot.output[[14]],plot.output[[15]],
             plot.output[[16]],plot.output[[17]],plot.output[[18]],
             nrow = 3)
# adding in discharge (models # 16 and 17) does affect other estimates, so I should not add it back in. 
# having precip. and turbidity (model 18) doe NOT seem to affect estimates, so maybe it's ok to have them together.

AICtab(mod.null,mod.output[[1]],mod.output[[2]],mod.output[[3]],
       mod.output[[4]],mod.output[[5]],mod.output[[6]],
       mod.output[[7]],mod.output[[8]],mod.output[[9]], 
       mod.output[[10]], mod.output[[11]],mod.output[[12]],mod.output[[13]],
       mod.output[[14]],mod.output[[15]],mod.output[[16]],mod.output[[17]],mod.output[[18]])

#                  dAIC df
# mod.output[[4]]   0.0 7 
# mod.output[[8]]   1.3 7 
# mod.output[[10]]  2.0 7 
# mod.output[[12]]  2.1 7 
# mod.output[[1]]   2.4 7 
# mod.output[[14]]  2.6 8 
# mod.output[[3]]   3.2 7 
# mod.output[[16]]  5.4 9 
# mod.output[[18]]  5.8 9 
# mod.output[[2]]  33.0 7 
# mod.output[[13]] 33.2 7 
# mod.output[[11]] 33.3 7 
# mod.output[[7]]  33.4 7 
# mod.output[[9]]  33.4 7 
# mod.output[[15]] 35.9 8 
# mod.output[[6]]  36.8 7 
# mod.null         37.0 3 
# mod.output[[17]] 37.2 9 
# mod.output[[5]]  42.4 7 

# all the lowest AIC models have turbidity as a predictor. AIC jumps up when precip is included instead. Most models with covars are better than the no covar null model. 


#### "for" loop to plot and save all model diagnostics ####

for(i in 1:18){
  pdf(paste("Output from analyses/22_CPCRW_2017_C2.r.fDOM_mods/model diagnostics/diagnostics.mod.", i, ".pdf",sep=""), width = 15, height =12)
  # INPUTS
  mod = mod.output[[i]]
  rawDatdf = as.data.frame(C2.r[,c(1,4)]) # original df w/ dates. that's all that's really used
  ResponseDatdf = as.data.frame(dat) # Transformed response data
  DateName = "day" #name of date column in rawDatdf
  MARSScheckDfFun(mod, rawDatdf, ResponseDatdf, DateName)
  Moddf2 <- MARSScheckDfFun(mod, rawDatdf, ResponseDatdf, DateName)
  # PLOT MODEL (base R)
  par(mfrow=c(3,3))
  plot(dat,ylab="fDOM (QSU)",xlab="",bty="n")
  title(main="C2-fDOM 01-01:08-13 \n Expected and predicted values of the x (hidden states) over observed")
  mod <- mod.output[[i]] #model results
  x=seq(1:length(dat))
  lines(x,Moddf2$states,col="red",lwd=2)
  lines(1:length(dat), Moddf2$statesLse ,col="red",lty=2)
  lines(1:length(dat), Moddf2$statesUse,col="red",lty=2)
  lines(x,Moddf2$X_fore,col="blue")
  # TIMESERIES STATE RESIDUALS (base R)
  plot.ts(residuals(mod.output[[i]],normalize=TRUE)$state.residuals[1,],
        ylab="Residual", main="")
  title(main="TIMESERIES STATE RES AND AUTOCORRELATION")
  abline(h=0, lty="dashed")
  # TIMESERIES AUTOCORRELATION  (base R)
  acf(residuals(mod.output[[i]],normalize=TRUE)$state.residuals[1,], na.action = na.omit)
  # NORMALITY OF STATE RESIDUALS  (ggplot)
  resids_mod <- residuals(mod.output[[i]])$state.residuals
  # Q-Q plot of innovations
  qqnorm(t(resids_mod), main="", pch=16, col="blue", 
         xlab=paste("shapiro test: ", shapiro.test(t(residuals(mod.output[[i]])$state.residuals))[1]), 
         ylab = varNames)
  title(main="NORMALITY OF STATE RESIDUALS")
  ## add y=x line for easier interpretation
  qqline(t(resids_mod))
# MAKE DF OF FITTED, OBS, & STD RESIDUALS
  # INPUTS
  mod = mod.output[[i]]
  rawDatdf = as.data.frame(C2.r[,c(1,4)]) # original df w/ dates. that's all that's really used
  ResponseDatdf = as.data.frame(dat) # Transformed response data
  DateName = "day" #name of date column in rawDatdf
  MARSScheckDfFun(mod, rawDatdf, ResponseDatdf, DateName)
  # PLOT OF FITTED VS OBSERVED (ggplot)
  p1 = fitVobsFun2(mod.output[[i]], rawDatdf, ResponseDatdf, DateName)
  # MAKE GRID TO MIX BASE AND GGPLOT GRAPHICS
  plot.new()
  pushViewport(viewport(layout = grid.layout(nrow = 3, ncol = 3)))
  # A helper function to define a region on the layout
  define_region <- function(row, col){
  viewport(layout.pos.row = row, layout.pos.col = col)
} 
  print(p1, vp = define_region(row = 2, col = 2))
  # PLOT OF RESIDUALS V OBSERVED (ggplot)
  p2 = resVobsFun2(mod.output[[i]], rawDatdf, ResponseDatdf, DateName)
  print(p2, vp = define_region(row = 2, col = 3))
  # PLOT OF RESIDUALS V FITTED (ggplot)
  p3 = resVfitFun(mod.output[[i]], rawDatdf, ResponseDatdf, DateName)
  print(p3, vp = define_region(row = 3, col = 1))
  dev.off()
}

#### script to plot residuals of covariates (needs automation) ####

plot.new()

pdf("Output from analyses/22_CPCRW_2017_C2.r.fDOM_mods/model diagnostics/resVcovs.mod.1.pdf", width = 12, height =12) 

# RESIDUALS VS COVARIATES (ggplot)
# see this for reasoning for why looking at residuals vs covariates in multiple regression doesn't make sense: https://stats.stackexchange.com/questions/118051/how-to-perform-residual-analysis-for-binary-dichotomous-independent-predictors-i
cov <- C2.r %>% select(j[[1]])
names(cov)
# PRODUCE DF
Moddf2 <- MARSScheckDfFun(mod, rawDatdf, ResponseDatdf, DateName)
# plot fitted vs covar
p1 = ggplot(Moddf2, aes(y = StateRes, x = cov$daylength)) +
  geom_point() +
  facet_grid(. ~var, scales = "free") +
  stat_smooth(method = "lm") +
  ylab("State residuals") +
  xlab("daylength")
p2 = ggplot(Moddf2, aes(y = StateRes, x = cov$Turbidity_FNU_filled_mean)) +
  geom_point() +
  facet_grid(. ~var, scales = "free") +
  stat_smooth(method = "lm") +
  ylab("State residuals") +
  xlab("Turbidity_FNU_filled_mean")
p3 = ggplot(Moddf2, aes(y = StateRes, x = cov$airtemp_100.1200cm_mean_mean)) +
  geom_point() +
  facet_grid(. ~var, scales = "free") +
  stat_smooth(method = "lm") +
  ylab("State residuals") +
  xlab("airtemp_C")
p4 = ggplot(Moddf2, aes(y = StateRes, x = cov$cum_prec_mm_mean)) +
  geom_point() +
  facet_grid(. ~var, scales = "free") +
  stat_smooth(method = "lm") +
  ylab("State residuals") +
  xlab("cum_prec_mm_mean")

grid.arrange(p1, p2, p3, p4)


dev.off()




FRCH_storm6_08_13_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm6_08_13_fDOM.csv")
FRCH_storm6_08_13_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm6_08_13_SPC.csv")
FRCH_storm6_08_13_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm6_08_13_Turb.csv")
#FRCH_storm7_08_23 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm7_08_23.csv")
FRCH_storm7_08_23_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm7_08_23_Q.csv")
#FRCH_storm7_08_23_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm7_08_23_NO3.csv")
FRCH_storm7_08_23_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm7_08_23_fDOM.csv")
FRCH_storm7_08_23_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm7_08_23_SPC.csv")
FRCH_storm7_08_23_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm7_08_23_Turb.csv")
#FRCH_storm8a_08_26 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8a_08_26.csv")
FRCH_storm8a_08_26_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8a_08_26_Q.csv")
#FRCH_storm8a_08_26_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8a_08_26_NO3.csv")
FRCH_storm8a_08_26_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8a_08_26_fDOM.csv")
FRCH_storm8a_08_26_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8a_08_26_SPC.csv")
FRCH_storm8a_08_26_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8a_08_26_Turb.csv")
#FRCH_storm8b_08_27 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8b_08_27.csv")
FRCH_storm8b_08_27_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8b_08_27_Q.csv")
#FRCH_storm8b_08_27_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8b_08_27_NO3.csv")
FRCH_storm8b_08_27_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8b_08_27_fDOM.csv")
FRCH_storm8b_08_27_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8b_08_27_SPC.csv")
FRCH_storm8b_08_27_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm8b_08_27_Turb.csv")
#FRCH_storm9_08_29 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm9_08_29.csv")
FRCH_storm9_08_29_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm9_08_29_Q.csv")
#FRCH_storm9_08_29_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm9_08_29_NO3.csv")
FRCH_storm9_08_29_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm9_08_29_fDOM.csv")
FRCH_storm9_08_29_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm9_08_29_SPC.csv")
FRCH_storm9_08_29_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm9_08_29_Turb.csv")
#FRCH_storm10_09_01 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm10_09_01.csv")
FRCH_storm10_09_01_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm10_09_01_Q.csv")
#FRCH_storm10_09_01_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm10_09_01_NO3.csv")
FRCH_storm10_09_01_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm10_09_01_fDOM.csv")
FRCH_storm10_09_01_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm10_09_01_SPC.csv")
FRCH_storm10_09_01_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm10_09_01_Turb.csv")
#FRCH_storm11a_09_22 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11a_09_22.csv")
FRCH_storm11a_09_22_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11a_09_22_Q.csv")
#FRCH_storm11a_09_22_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11a_09_22_NO3.csv")
FRCH_storm11a_09_22_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11a_09_22_fDOM.csv")
FRCH_storm11a_09_22_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11a_09_22_SPC.csv")
FRCH_storm11a_09_22_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11a_09_22_Turb.csv")
#FRCH_storm11b_09_24 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FFRCH_storm11b_09_24.csv")
FRCH_storm11b_09_24_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11b_09_24_Q.csv")
#FRCH_storm11b_09_24_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11b_09_24_NO3.csv")
FRCH_storm11b_09_24_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11b_09_24_fDOM.csv")
FRCH_storm11b_09_24_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11b_09_24_SPC.csv")
FRCH_storm11b_09_24_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm11b_09_24_Turb.csv")
# normalize
dfList <- Filter(function(x) is(x, "data.frame"), mget(ls()))
for(i in 1:length(dfList)) {
dfList[[i]][["datavalue"]] =
(dfList[[i]][["datavalue"]] - min(dfList[[i]][["datavalue"]], na.rm=T)) / (max(dfList[[i]][["datavalue"]], na.rm=T) - min(dfList[[i]][["datavalue"]], na.rm=T))
}
list2env(dfList ,.GlobalEnv)
View
View(FRCH_storm10_09_01_fDOM)
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
attributes(FRCH_2018_test_beta$DateTime)$tzone <- 'America/Anchorage'
dfList <- Filter(function(x) is(x, "data.frame"), mget(ls()))
for(i in 1:length(dfList)) {
dfList[[i]][["datavalue"]] =
(dfList[[i]][["datavalue"]] - min(dfList[[i]][["datavalue"]], na.rm=T)) / (max(dfList[[i]][["datavalue"]], na.rm=T) - min(dfList[[i]][["datavalue"]], na.rm=T))
}
list2env(dfList ,.GlobalEnv)
# Turbidity test
turb <- FRCH_2018_test_beta[,-c(5,6,7)] # filtering out Site and year
View(turb)
rm(FRCH_2018_test_beta)
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
attributes(FRCH_2018_test_beta$DateTime)$tzone <- 'America/Anchorage'
# Turbidity test
turb <- FRCH_2018_test_beta[,-c(5,6,7)] # filtering out Site and year
rm(FRCH_2018_test_beta)
# Normalize data #
dfList <- Filter(function(x) is(x, "data.frame"), mget(ls()))
for(i in 1:length(dfList)) {
dfList[[i]][["datavalue"]] =
(dfList[[i]][["datavalue"]] - min(dfList[[i]][["datavalue"]], na.rm=T)) / (max(dfList[[i]][["datavalue"]], na.rm=T) - min(dfList[[i]][["datavalue"]], na.rm=T))
}
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
attributes(FRCH_2018_test_beta$DateTime)$tzone <- 'America/Anchorage'
# Turbidity test
turb <- FRCH_2018_test_beta[,-c(5,6,7)] # filtering out Site and year
rm(FRCH_2018_test_beta)
turb <- na.omit(turb)
# Normalize data #
dfList <- Filter(function(x) is(x, "data.frame"), mget(ls()))
for(i in 1:length(dfList)) {
dfList[[i]][["datavalue"]] =
(dfList[[i]][["datavalue"]] - min(dfList[[i]][["datavalue"]], na.rm=T)) / (max(dfList[[i]][["datavalue"]], na.rm=T) - min(dfList[[i]][["datavalue"]], na.rm=T))
}
FRCH_storm5_08_04_Q <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm5_08_04_Q.csv")
FRCH_storm5_08_04_NO3 <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm5_08_04_NO3.csv")
FRCH_storm5_08_04_fDOM <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm5_08_04_fDOM.csv")
FRCH_storm5_08_04_SPC <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm5_08_04_SPC.csv")
FRCH_storm5_08_04_turb <- read_csv("~/Documents/Storms/Storm_Events/2018/FRCH/FRCH_storm5_08_04_Turb.csv")
# normalize
dfList <- Filter(function(x) is(x, "data.frame"), mget(ls()))
for(i in 1:length(dfList)) {
dfList[[i]][["datavalue"]] =
(dfList[[i]][["datavalue"]] - min(dfList[[i]][["datavalue"]], na.rm=T)) / (max(dfList[[i]][["datavalue"]], na.rm=T) - min(dfList[[i]][["datavalue"]], na.rm=T))
}
list2env(dfList ,.GlobalEnv)
# FRCH #
#fxn: plot hysteresis loop #
hyst_plot = function(dat_Q, dat_response, site, response_var, storm_num) {
dat.p = ggplot(data = dat_Q,
aes(x=(dat_Q$datavalue),
y=(dat_response$datavalue),
color = as.numeric(dat_Q$valuedatetime))) +
geom_point() +
scale_colour_gradientn(colors = rainbow(3)) +
theme_bw() +
theme(legend.position="none") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold")) +
ylab(paste(site, response_var))+
xlab("Normalized Discharge") +
ggtitle(paste("Storm", storm_num))
return(dat.p)
}
FRCH_storm5_08_04_fDOM[c(180:182),3] <- NA
FRCH_storm5_08_04_SPC[c(180:182),3] <- NA
View(FRCH_storm5_08_04_fDOM)
View(FRCH_storm5_08_04_NO3)
FRCH_storm5_08_04_NO3.p = hyst_plot(FRCH_storm5_08_04_Q, FRCH_storm5_08_04_NO3, "FRCH", "NO3", "0804")
FRCH_storm5_08_04_fDOM.p = hyst_plot(FRCH_storm5_08_04_Q, FRCH_storm5_08_04_fDOM, "FRCH", "fDOM", "0804")
FRCH_storm5_08_04_SPC.p = hyst_plot(FRCH_storm5_08_04_Q, FRCH_storm5_08_04_SPC, "FRCH", "SPC", "0804")
FRCH_storm5_08_04_turb.p = hyst_plot(FRCH_storm5_08_04_Q, FRCH_storm5_08_04_turb, "FRCH", "turb", "0804")
View(FRCH_storm5_08_04_fDOM.p$data)
View(FRCH_storm5_08_04_fDOM.p)
plot(FRCH_storm5_08_04_fDOM.p$plot_env)
View(FRCH_storm5_08_04_fDOM.p$plot_env)
names(FRCH_storm5_08_04_Q)
View(FRCH_storm5_08_04_Q)
fdom.storm5 <- left_join(FRCH_storm5_08_04_Q, FRCH_storm5_08_04_fDOM, by = "valuedatetime")
View(fdom.storm5)
plot(fdom.storm5$datavalue.x, fdom.storm5$datavalue.y)
str(FRCH_storm5_08_04_fDOM)
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
str(FRCH_2018_test_beta)
str(FRCH_storm5_08_04_fDOM)
cols.1 <- c("datavalue.x", "datavalue.y")
fdom.storm5[cols.1] <- log(fdom.storm5[cols.1])
fdom.storm5 <- mutate(limb = ifelse(valuedatetime < valuedatetime[which.max(datavalue.x)], "ascending", "descending"))
fdom.storm5 <- fdom.storm5 %>%  mutate(limb = ifelse(valuedatetime < valuedatetime[which.max(datavalue.x)], "ascending", "descending"))
fdom.storm5_ascending <- filter(fdom.storm5, limb == "ascending")
fdom.storm5_ascending <-  fdom.storm5_ascending[!is.na(fdom.storm5_ascending$datavalue.y), ]
frch.beta.storm5 <- fdom.storm5_ascending %>%
summarize(beta = slope(datavalue.x, datavalue.y))
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
frch.beta.storm5 <- fdom.storm5_ascending %>%
summarize(beta = slope(datavalue.x, datavalue.y))
lm(fdom.storm5_ascending$datavalue.y ~ fdom.storm5_ascending$datavalue.x)
fdom.storm5_ascending <-  fdom.storm5_ascending[!is.na(fdom.storm5_ascending$datavalue.y), ]
View(fdom.storm5_ascending)
fdom.storm5_ascending <-  fdom.storm5_ascending[!is.na(fdom.storm5_ascending$datavalue.x), ]
fdom.storm5_ascending <- fdom.storm5_ascending[-c(1:3),]
frch.beta.storm5 <- fdom.storm5_ascending %>%
summarize(beta = slope(datavalue.x, datavalue.y))
lm(fdom.storm5_ascending$datavalue.y ~ fdom.storm5_ascending$datavalue.x)
plot(fdom.storm5$datavalue.x, fdom.storm5$datavalue.y)
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
attributes(FRCH_2018_test_beta$DateTime)$tzone <- 'America/Anchorage'
cols <- c("fDOM.QSU","nitrateuM", "SpCond.uScm", "Turbidity.FNU", "MeanDischarge")
FRCH_2018_test_beta[cols] <- log(FRCH_2018_test_beta[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
FRCH_2018_test_beta.NO3 <- FRCH_2018_test_beta[,-c(5,7,8)] # only have NO3 as the response
FRCH_2018_test_beta.fDOM <- FRCH_2018_test_beta[,-c(6:8)] # only have fdom as the response
FRCH_2018_test_beta.SPC <- FRCH_2018_test_beta[,-c(5,6,8)] # only have fdom as the response
FRCH_2018_test_beta.turb <- FRCH_2018_test_beta[,-c(5:7)] # only have fdom as the response
# NO3
all_NO3_test <- FRCH_2018_test_beta %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num, Site) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
View(beta.all.no3)
View(all_NO3_ascending)
# NO3
all_NO3_test <- FRCH_2018_test_beta.NO3 %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num, Site) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
View(beta.all.no3)
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
?summarise
library(here)
library(tidyverse)
library(boot)
library(broom)
library(purrr)
library(viridis)
library(readr)
library(tidyverse)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(here)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(readr)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(SLOPE)
library(wesanderson)
library(ggpubr)
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
attributes(FRCH_2018_test_beta$DateTime)$tzone <- 'America/Anchorage'
cols <- c("fDOM.QSU","nitrateuM", "SpCond.uScm", "Turbidity.FNU", "MeanDischarge")
FRCH_2018_test_beta[cols] <- log(FRCH_2018_test_beta[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
# Try it by all sites per response
FRCH_2018_test_beta.NO3 <- FRCH_2018_test_beta[,-c(5,7,8)] # only have NO3 as the response
# NO3
all_NO3_test <- FRCH_2018_test_beta.NO3 %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
library(ggpubr)
?group_by
beta.all.no3 <- all_NO3_ascending %>% group_by(all_NO3_ascending$storm.num) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
View(beta.all.no3)
str(all_NO3_ascending)
summarise(all_NO3_ascending, beta = slope(MeanDischarge, nitrateuM))
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read_csv("~/Desktop/FRCH_2018_test_beta.csv")
attributes(FRCH_2018_test_beta$DateTime)$tzone <- 'America/Anchorage'
cols <- c("fDOM.QSU","nitrateuM", "SpCond.uScm", "Turbidity.FNU", "MeanDischarge")
FRCH_2018_test_beta[cols] <- log(FRCH_2018_test_beta[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
str(FRCH_2018_test_beta)
beta.all.no3 <- all_NO3_ascending %>% group_by(as.factor(storm.num)) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
FRCH_2018_test_beta.NO3 <- FRCH_2018_test_beta[,-c(5,7,8)] # only have NO3 as the response
# NO3
all_NO3_test <- FRCH_2018_test_beta.NO3 %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
beta.all.no3 <- all_NO3_ascending %>% group_by(as.factor(storm.num)) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
summarise(all_NO3_ascending, beta = slope(MeanDischarge, nitrateuM))
# Try it by all sites per response
FRCH_2018_test_beta$storm.num <- as.factor(FRCH_2018_test_beta$storm.num)
str(FRCH_2018_test_beta)
FRCH_2018_test_beta.NO3 <- FRCH_2018_test_beta[,-c(5,7,8)] # only have NO3 as the response
# NO3
all_NO3_test <- FRCH_2018_test_beta.NO3 %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
str(all_NO3_ascending)
View(beta.all.no3)
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarise(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
summarise(all_NO3_ascending, beta = slope(MeanDischarge, nitrateuM))
head(beta.all.no3)
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarise(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
all_NO3_ascending % > %
group_by(storm.num) % > %
summarise(beta = slope(MeanDischarge, nitrateuM))
all_NO3_ascending %>%
group_by(storm.num) %>%
summarise(beta = slope(MeanDischarge, nitrateuM))
str(all_NO3_ascending)
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num, Site) %>%
summarise(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
beta.all.no3
all_NO3_ascending %>%
group_by(storm.num) %>%
summarise(beta = mean(nitrateuM))
class(all_NO3_ascending)
write.csv(all_NO3_ascending, "~/Desktop/Frances.csv")
#### FI ? #####
storms.2019.2020 <- read.csv("Output_from_analysis/06_HI_fire_permafrost_script/storms.2019.2020.csv")
cols <- c("fDOM.QSU","nitrateuM", "SpCond.uScm", "Turbidity.FNU", "MeanDischarge")
storms.2019.2020[cols] <- log(storms.2019.2020[cols]) # making concentrations and Q log transformed
MOOS.2019 <- storms.2019.2020 %>% filter(Site == "MOOS" & year == "2019") # filtering out Site and year
MOOS.2019.fDOM <- MOOS.2019[,-c(6,7,8)] # making it so it is just fDOM
POKE.2019 <- storms.2019.2020 %>% filter(Site == "POKE" & year == "2019") # filtering out Site and year
POKE.2019.fDOM <- POKE.2019[,-c(6,7,8)] # making it so it is just fDOM
#STRT.2019 <- storms.2019.2020 %>% filter(Site == "STRT" & year == "2019") # filtering out Site and year
#STRT.2019.fDOM <- STRT.2019[,-c(6,7,8)] # making it so it is just fDOM
#fDOM_T <- storms.2019.2020 %>% group_by(Site, year, storm.num) %>%
# mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
# storm 1 #
#Moos_test_ascending_storm1 <- filter(Moos_test_ascending, storm.num == "storm1")
#Moos_test_ascending_storm1 <-  Moos_test_ascending_storm1[!is.na(Moos_test_ascending_storm1$fDOM.QSU), ]
#slope(Moos_test_ascending_storm1$MeanDischarge, Moos_test_ascending_storm1$fDOM.QSU)
#summary(lm(Moos_test_ascending_storm1$fDOM.QSU ~ Moos_test_ascending_storm1$MeanDischarge))
# try it by all of moos #
Moos_test <- MOOS.2019.fDOM %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
Moos_test_ascending <- filter(Moos_test, limb == "ascending")
Moos_test_ascending <-  Moos_test_ascending[!is.na(Moos_test_ascending$fDOM.QSU), ]
Poke_test <- POKE.2019.fDOM %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
Poke_test_ascending <- filter(Poke_test, limb == "ascending")
Poke_test_ascending <-  Poke_test_ascending[!is.na(Poke_test_ascending$fDOM.QSU), ]
#################### test plot ##################################################
ggplot(data = Moos_test_ascending, aes(x = MeanDischarge, y = fDOM.QSU, color = storm.num)) +
geom_point()
beta.1 <- Moos_test_ascending %>% group_by(storm.num) %>%
summarize(beta = slope(MeanDischarge, fDOM.QSU))
lm(Moos_test_ascending_1$fDOM.QSU ~ Moos_test_ascending$MeanDischarge)
Moos_test_ascending_1 <- filter(Moos_test_ascending, storm.num == "storm1")
Moos_test_1 <- filter(Moos_test, storm.num == "storm1")
ggplot(data = Moos_test_1, aes(MeanDischarge, fDOM.QSU)) +
geom_point()
lm(Moos_test_ascending_1$fDOM.QSU ~ Moos_test_ascending_1$MeanDischarge)
Moos_test_ascending_4 <- filter(Moos_test_ascending, storm.num == "storm4")
Moos_test_4 <- filter(Moos_test, storm.num == "storm4")
ggplot(data = Moos_test_4, aes(MeanDischarge, fDOM.QSU)) +
geom_point()
lm(Moos_test_ascending_4$fDOM.QSU ~ Moos_test_ascending_4$MeanDischarge)
Moos_test_ascending_5 <- filter(Moos_test_ascending, storm.num == "storm5")
Moos_test_5 <- filter(Moos_test, storm.num == "storm5")
ggplot(data = Moos_test_ascending_5, aes(MeanDischarge, fDOM.QSU)) +
geom_point()
lm(Moos_test_ascending_5$fDOM.QSU ~ Moos_test_ascending_5$MeanDischarge)
### poke test ###
ggplot(data = Poke_test_ascending, aes(x = MeanDischarge, y = fDOM.QSU, color = storm.num)) +
geom_point()
beta.poke <- Poke_test_ascending %>% group_by(storm.num) %>%
summarize(beta = slope(MeanDischarge, fDOM.QSU))
Poke_test_ascending_1 <- filter(Poke_test_ascending, storm.num == "storm1")
Poke_test_1 <- filter(Poke_test, storm.num == "storm1")
ggplot(data = Poke_test_1, aes(MeanDischarge, fDOM.QSU)) +
geom_point()
lm(Poke_test_ascending_1$fDOM.QSU ~ Poke_test_ascending_1$MeanDischarge)
Moos_test_ascending_4 <- filter(Moos_test_ascending, storm.num == "storm4")
Moos_test_4 <- filter(Moos_test, storm.num == "storm4")
ggplot(data = Moos_test_4, aes(MeanDischarge, fDOM.QSU)) +
geom_point()
lm(Moos_test_ascending_4$fDOM.QSU ~ Moos_test_ascending_4$MeanDischarge)
Moos_test_ascending_5 <- filter(Moos_test_ascending, storm.num == "storm5")
Moos_test_5 <- filter(Moos_test, storm.num == "storm5")
ggplot(data = Moos_test_ascending_5, aes(MeanDischarge, fDOM.QSU)) +
geom_point()
lm(Moos_test_ascending_5$fDOM.QSU ~ Moos_test_ascending_5$MeanDischarge)
MOOS_chem_2019 <- read_csv("Q_Chem/MOOS/MOOS_chem_2019.csv")
ggplot() +
geom_point(data = MOOS_chem_2019, aes(DateTime, MeanDischarge), color = "red") +
geom_point(data = MOOS_chem_2019, aes(DateTime, fDOM.QSU.mn * 10), color = "blue")
EXO_aord <- read_csv("~/Documents/DoD_2019/EXO_processed/EXO.aord.csv")
MOOS_2019_EXO <- filter(EXO_aord, site.ID == "MOOS")
MOOS_2019_EXO$datetimeAK <- as.POSIXct(MOOS_2019_EXO$datetimeAK, tz="America/Anchorage")
MOOS_2019_EXO$DateTime <- MOOS_2019_EXO$datetimeAK
MOOS_2019_Q <- read_csv("~/Documents/DoD_2019/Q/Final_Q/MOOS/MOOS.csv")
MOOS_2019_Q$DateTime <- as.POSIXct(MOOS_2019_Q$DateTime, tz = "America/Anchorage")
moos.q.chem <- full_join(MOOS_2019_Q, MOOS_2019_EXO) # this wo
moos.q.chem <- moos.q.chem[,-c(4,5,6,8,9,10,11,12,14,16,17,18,19,20,21,22,23)]
ggplot() +
geom_point(data = moos.q.chem, aes(DateTime, MeanDischarge), color = "red") +
geom_point(data = moos.q.chem, aes(DateTime, Turbidity.FNU.mn * 10), color = "green") +
geom_point(data = moos.q.chem, aes(DateTime, fDOM.QSU.mn * 10), color = "blue")
ggplot() +
geom_point(data = moos.q.chem, aes(DateTime, MeanDischarge), color = "red") +
geom_point(data = moos.q.chem, aes(DateTime, Turbidity.FNU.mn), color = "blue")
POKE_chem_2019 <- read_csv("Q_Chem/POKE/POKE_chem_2019.csv")
ggplot() +
geom_point(data = POKE_chem_2019, aes(DateTime, MeanDischarge), color = "red") +
geom_point(data = POKE_chem_2019, aes(DateTime, Turbidity.FNU.mn * 10), color = "green") +
geom_point(data = POKE_chem_2019, aes(DateTime, fDOM.QSU.mn * 10), color = "blue")
# merge HI and beta
#HI_moos_2019 <- read.csv("Output_from_analysis/06_HI_fire_permafrost_script/HI.moos.2019.csv")
#HI.moos.2019.fdom <- HI_moos_2019 %>% filter(response == "fDOM")
#moos.2019 <- left_join(fDOM_Test_6, HI.moos.2019.fdom)  # joining beta and HI
# Try it by all sites per response
storms.2019.2020.NO3 <- storms.2019.2020[,-c(5,7,8)] # only have NO3 as the response
storms.2019.2020.fDOM <- storms.2019.2020[,-c(6:8)] # only have fdom as the response
storms.2019.2020.SPC <- storms.2019.2020[,-c(5,6,8)] # only have fdom as the response
storms.2019.2020.turb <- storms.2019.2020[,-c(5:7)] # only have fdom as the response
all_NO3_test <- storms.2019.2020.NO3 %>% group_by(storm.num, year) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num, Site, year) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
head(beta.all.no3)
source('~/Documents/Storms/R_Scripts/06_HI_fire_permafrost_year.R', echo=TRUE)
View(beta.all.no3)
View(beta.all.no3)
##############################################################################################################
####################### Beta Test #######################################################################
##############################################################################################################
FRCH_2018_test_beta <- read.csv("~/Desktop/FRCH_2018_test_beta.csv")
cols <- c("fDOM.QSU","nitrateuM", "SpCond.uScm", "Turbidity.FNU", "MeanDischarge")
FRCH_2018_test_beta[cols] <- log(FRCH_2018_test_beta[cols]) # making concentrations and Q log transformed
slope <- function(x, y){
mean_x <- mean(x)
mean_y <- mean(y)
nom <- sum((x - mean_x)*(y-mean_y))
denom <- sum((x - mean_x)^2)
m <- nom / denom
return(m)
}
str(FRCH_2018_test_beta)
FRCH_2018_test_beta.NO3 <- FRCH_2018_test_beta[,-c(5,7,8)] # only have NO3 as the response
# NO3
all_NO3_test <- FRCH_2018_test_beta.NO3 %>% group_by(storm.num) %>%
mutate(limb = ifelse(DateTime < DateTime[which.max(MeanDischarge)], "ascending", "descending"))
all_NO3_ascending <- filter(all_NO3_test, limb == "ascending")
all_NO3_ascending <-  all_NO3_ascending[!is.na(all_NO3_ascending$nitrateuM), ]
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarize_(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarize(beta = slope(MeanDischarge, nitrateuM)) # this works just like the beta one that is for an individual site
View(beta.all.no3)
beta.all.no3 <- all_NO3_ascending %>% group_by(storm.num) %>%
summarize(beta = mean(nitrateuM)) # this works just like the beta one that is for an individual site
View(CARI_storm1_05_08_Q)
reticulate::repl_python()
CARI.hyst.results.list = list(py$hysdict_CARI_storm1_05_08_NO3,
)
CARI.hyst.results.list = list(py$hysdict_CARI_storm1_05_08_NO3
)
CARI.hyst.results.list.2 = list()
for (i in 1:length(CARI.hyst.results.list)){
CARI.hyst.results.list.2[[i]] = as.data.frame(t(as.numeric(c(
CARI.hyst.results.list[[i]][["HI_mean_with_Interp"]],
CARI.hyst.results.list[[i]][["HI_standard_deviation_with_Interp"]],
CARI.hyst.results.list[[i]][["Normalized slope of response"]],
CARI.hyst.results.list[[i]][["interpolated Max width of response"]],
CARI.hyst.results.list[[i]][["Min response"]],
CARI.hyst.results.list[[i]][["Max response"]],
CARI.hyst.results.list[[i]][["Peak Q"]]
))))
names(CARI.hyst.results.list.2[[i]]) = c("HI_mean_Interp", "HI_sd_with_Interp", "N.S.", "Max_width_Interp", "Min_response", "Max_response", "Peak_Q")
}
HIs.list = list()
HIs.tests = list()
for (i in 1:length(CARI.hyst.results.list)){
HIs.list[[i]] = unlist(CARI.hyst.results.list[[i]][["Hysteresis_Index"]],recursive=FALSE)
HIs.tests[[i]] = as.data.frame(t(round(as.numeric(c(shapiro.test(HIs.list[[i]])$statistic, shapiro.test(HIs.list[[i]])$p.value,
t.test(HIs.list[[i]], mu=0)$statistic, t.test(HIs.list[[i]], mu=0)$p.value,
t.test(HIs.list[[i]], mu=0)$conf.int[1],t.test(HIs.list[[i]], mu=0)$conf.int[2],
wilcox.test(HIs.list[[i]], mu=0)$statistic, wilcox.test(HIs.list[[i]], mu=0)$p.value)), 4)))
names(HIs.tests[[i]]) = c("ShapiroTest.W", "ShapiroTest.p", "t.test.stat", "t.test.p", "t.test.CIlow", "t.test.CIhigh",
"wilcox.test.stat", "wilcox.test.p")
}
reticulate::repl_python()
